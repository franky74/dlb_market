# -*- coding: utf-8 -*-
"""DLB_ModelGenerator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BY1lyrU90GR2iH7Rc5eqtWEA5Lh-69Sn

# **Text Categorization - Market & Service ** 
##DLB - Proposals - Predict Market using combination of client and proposal description

Vote Classifiers from:


*   Naive Bayes
*   Linear Support Vector
*   Logistic Regression
*   Doc2Vec 
*   Keras 

Currently the train:test ratio is 70:30 - change it in 

```
train_size = int(len(df) * .7)
```

Monitor is using 'val_loss' - change it in 


```
monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')
```

Epoch is set to 100 but it will stop using EarlyStopping monitor



```
epochs = 100
```
"""

import logging
import pandas as pd
import numpy as np
import tensorflow as tf
import gensim
import nltk
import pickle as p
import matplotlib.pyplot as plt
import re
import nltk
import itertools
import os

from numpy import random
from nltk.corpus import stopwords
from nltk.classify import ClassifierI
from bs4 import BeautifulSoup

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn import svm, datasets
from sklearn.preprocessing import LabelBinarizer, LabelEncoder
from sklearn.utils.multiclass import unique_labels
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.pipeline import Pipeline

from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Input, Conv2D, MaxPool2D, Dense
from keras.preprocessing import text, sequence
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras import utils as utils_k
from sklearn import utils as utils_skl

from tqdm import tqdm
tqdm.pandas(desc="progress-bar")
from gensim.models import Doc2Vec
from gensim.models.doc2vec import TaggedDocument

def clean_text(text):
    """
        text: a string
        
        return: modified initial string
    """
    text = BeautifulSoup(text, "lxml").text # HTML decoding
    text = text.lower() # lowercase text
    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text
    return text
  
## change this value to predict either market or service
label_name = "market"

nltk.download('stopwords')
# %matplotlib inline

if label_name == "market":
  df = pd.read_csv('https://apps.dlbassociates.com/register/market.csv')
  lbl = pd.read_csv('https://apps.dlbassociates.com/register/lbl_mkt.csv')
else:
  df = pd.read_csv('https://apps.dlbassociates.com/register/service.csv')
  lbl = pd.read_csv('https://apps.dlbassociates.com/register/lbl_svc.csv')

df = df[pd.notnull(df[label_name])]

#plt.figure(figsize=(10,4))
#df.market.value_counts().plot(kind='bar');

#def print_plot(index):
#    example = df[df.index == index][['desc', 'market']].values[0]
#    if len(example) > 0:
#        print(example[0])
#        print('Market:', example[1])

REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))

df['combined'] = df['combined'].apply(clean_text)
df['combined'].apply(lambda x: len(x.split(' '))).sum()

x_values = df.combined
y_values = df[label_name]

x_train, x_test, y_train, y_test = train_test_split(x_values, y_values, test_size=0.3)

my_lbls = lbl[label_name]

"""##Various Helpers"""

def plot_confusion_matrix(cm,
                          target_names,
                          title='Confusion matrix',
                          cmap=None,
                          normalize=True):
    """
    given a sklearn confusion matrix (cm), make a nice plot

    Arguments
    ---------
    cm:           confusion matrix from sklearn.metrics.confusion_matrix

    target_names: given classification classes such as [0, 1, 2]
                  the class names, for example: ['high', 'medium', 'low']

    title:        the text to display at the top of the matrix

    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm
                  see http://matplotlib.org/examples/color/colormaps_reference.html
                  plt.get_cmap('jet') or plt.cm.Blues

    normalize:    If False, plot the raw numbers
                  If True, plot the proportions

    Usage
    -----
    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by
                                                              # sklearn.metrics.confusion_matrix
                          normalize    = True,                # show proportions
                          target_names = y_labels_vals,       # list of names of the classes
                          title        = best_estimator_name) # title of graph

    Citiation
    ---------
    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html

    """
    import matplotlib.pyplot as plt
    import numpy as np
    import itertools

    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        plt.xticks(tick_marks, target_names, rotation=45)
        plt.yticks(tick_marks, target_names)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]


    thresh = cm.max() / 1.5 if normalize else cm.max() / 2
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        if normalize:
            plt.text(j, i, "{:0.4f}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
        else:
            plt.text(j, i, "{:,}".format(cm[i, j]),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")


    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))
    plt.show()

def label_sentences(corpus, label_type):
    """
    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.
    We do this by using the TaggedDocument method. The format will be "TRAIN_i" or "TEST_i" where "i" is
    a dummy index of the post.
    """
    labeled = []
    for i, v in enumerate(corpus):
        label = label_type + '_' + str(i)
        labeled.append(TaggedDocument(v.split(), [label]))
    return labeled
  
def get_vectors(model, corpus_size, vectors_size, vectors_type):
    """
    Get vectors from trained doc2vec model
    :param doc2vec_model: Trained Doc2Vec model
    :param corpus_size: Size of the data
    :param vectors_size: Size of the embedding vectors
    :param vectors_type: Training or Testing vectors
    :return: list of vectors
    """
    vectors = np.zeros((corpus_size, vectors_size))
    for i in range(0, corpus_size):
        prefix = vectors_type + '_' + str(i)
        vectors[i] = model.docvecs[prefix]
    return vectors

class VoteClassifier(ClassifierI):
  def __init__(self, *classifiers):
    self._classifiers = classifiers
    
  def classify(self, features):
    votes = []
    for c in self._classifiers:
      v = c.classify(features)
      votes.append(v)
    return mode(votes)
  
  def confidence(self, features):
    votes = []
    for c in self.classifiers:
      v = c.classify(features)
      votes.append(v)
      
    choice_votes = votes.count(mode(votes))
    conf = choice_votes / len(votes)
    return conf
  
def predicted_value(text):
  feats = find_features(text)
  
  return voted_classifier.classify(feats), voted_classifier.confidence(feats)

"""##Naive Bayes"""

## Naive Bayes
clsf_naive_bayes = Pipeline([('vect', CountVectorizer()),
                             ('tfidf', TfidfTransformer()),
                             ('clf', MultinomialNB()),
                            ])
clsf_naive_bayes.fit(x_train, y_train)
file_naive_bayes = "clsf_naive_bayes_" + label_name + ".pickle"
p.dump(clsf_naive_bayes, open(file_naive_bayes, 'wb'))

# Report - Naive Bayes
pred_naive_bayes = clsf_naive_bayes.predict(x_test)
acc_naive_bayes = accuracy_score(pred_naive_bayes, y_test) * 100

"""## Linear Support Vector Machine"""

## Linear Support Vector Machine
clsf_svm = Pipeline([('vect', CountVectorizer()),
                ('tfidf', TfidfTransformer()),
                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),
               ])
clsf_svm.fit(x_train, y_train)
file_svm = "clsf_svm_" + label_name + ".pickle"
p.dump(clsf_svm, open(file_svm, 'wb'))

# Report - Linear Support Vector Machine
pred_svm = clsf_svm.predict(x_test)
acc_svm = accuracy_score(pred_svm, y_test) * 100

"""##Logistic Regression"""

## Logistic Regression
clsf_logistic_reg = Pipeline([('vect', CountVectorizer()),
                ('tfidf', TfidfTransformer()),
                ('clf', LogisticRegression(n_jobs=1, C=1e5)),
               ])
clsf_logistic_reg.fit(x_train, y_train)
file_logistic_reg = "clsf_logistic_reg_" + label_name + ".pickle"
p.dump(clsf_logistic_reg, open(file_logistic_reg, 'wb'))

# Report - Logistic Regression
pred_logistic_reg = clsf_logistic_reg.predict(x_test)
acc_logistic_reg = accuracy_score(pred_logistic_reg, y_test) * 100

"""## Doc2vec and Logistic Regression"""

## Doc2vec and Logistic Regression
x_train_labeled = label_sentences(x_train, 'train')
x_test_labeled = label_sentences(x_test, 'test')
all_data = x_train_labeled + x_test_labeled

clsf_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)
clsf_dbow.build_vocab([x for x in tqdm(all_data)])
for epoch in range(30):
    clsf_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)
    clsf_dbow.alpha -= 0.002
    clsf_dbow.min_alpha = clsf_dbow.alpha
    
train_vectors_dbow = get_vectors(clsf_dbow, len(x_train_labeled), 300, 'train')
test_vectors_dbow = get_vectors(clsf_dbow, len(x_test_labeled), 300, 'test')

clsf_d2v = LogisticRegression(n_jobs=1, C=1e5)
clsf_d2v = clsf_d2v.fit(train_vectors_dbow, y_train)

file_d2v= "clsf_d2v_" + label_name + ".pickle"
p.dump(clsf_d2v, open(file_d2v, 'wb'))

# Report - Doc2Vec
pred_d2v = clsf_d2v.predict(test_vectors_dbow)
acc_d2v = accuracy_score(pred_d2v, y_test) * 100

"""## Keras - Sequenctial"""

## Keras - Sequenctial

#tokenize data
train_size = int(len(df) * .7)

train_label = df[label_name][:train_size]
train_feat = df['combined'][:train_size]

test_label = df[label_name][train_size:]
test_feat = df['combined'][train_size:]

max_words = 10000
tokenize = text.Tokenizer(num_words=max_words, char_level=False)

tokenize.fit_on_texts(train_feat)
tokenize.fit_on_texts(test_feat)

x_train = tokenize.texts_to_matrix(train_feat)
x_test = tokenize.texts_to_matrix(test_feat)

encoder = LabelEncoder()
encoder.fit(train_label)

y_train = encoder.transform(train_label)
y_test = encoder.transform(test_label)

num_classes = np.max(y_train) + 1
y_train = utils_k.to_categorical(y_train, num_classes)
y_test = utils_k.to_categorical(y_test, num_classes)

batch_size = 32
epochs = 100

ckfile = "clsf_keras_" + label_name + ".hdf5"
monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=0, mode='auto')
checkpointer = ModelCheckpoint(filepath=ckfile, verbose=0, save_best_only=True)

assert not tf.executing_eagerly()
# Build the model
model_keras = Sequential()
model_keras.add(Dense(512, input_shape=(max_words,)))
model_keras.add(Activation('relu'))
model_keras.add(Dropout(0.5))
model_keras.add(Dense(num_classes))
model_keras.add(Activation('softmax'))

model_keras.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy','mae'])
              
model_keras.fit(x_train, y_train,
          validation_data=(x_test, y_test),
          callbacks=[monitor, checkpointer],
          batch_size=batch_size,
          epochs=epochs,
          verbose=1)

model_keras.load_weights(ckfile)

score = model_keras.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)

# Report - Keras
acc_keras = score[1] * 100

model_keras.save("model_keras_" + label_name + ".h5")

#pred = model.predict(x_test)
#pred = np.argmax(pred, axis=1)
#y_test2 = np.argmax(y_test, axis=1)

#cm = confusion_matrix(y_test2, pred)
#np.set_printoptions(precision=2)

#plot_confusion_matrix(cm, normalize=False, target_names=my_cats, title='Confusion matrix - market, without normalization')
#plot_confusion_matrix(cm, normalize=True, target_names=my_cats,title='Confusion matrix - market, with normalization')

"""## Vote"""

voted_classifier = VoteClassifier(clsf_naive_bayes,
                                  clsf_svm,
                                  clsf_logistic_reg,
                                  clsf_d2v,
                                  model_keras)

"""# RESULT"""

print('1. accuracy - Naive Bayes, %s' % acc_naive_bayes)
#print(classification_report(y_test, pred_naive_bayes, target_names=my_lbls))

print('2. accuracy - Linear Support Vector, %s' % acc_svm)
#print(classification_report(y_test, pred_svm, target_names=my_lbls))

print('3. accuracy - Logistic Regression, %s' % acc_logistic_reg)
#print(classification_report(y_test, pred_logistic_reg, target_names=my_lbls))

print('4. accuracy - Doc2vec, %s' % acc_d2v)
#print(classification_report(y_test, pred_d2v, target_names=my_lbls))

print('5. accuracy - Keras, %s' % acc_keras)